{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Use only GPU 0\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import logging, os\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from src.plot.general import plot_scalar_dictionary\n",
    "from src.plot.series import *\n",
    "from src.plot.vaeplot import *\n",
    "from src.plot.fmm import plot_fmm_wave_from_coefficients\n",
    "from src.utils.metrics import *\n",
    "from src.utils.math import *\n",
    "from src.utils.general_functions import *\n",
    "from src.utils.preprocessing import *\n",
    "from src.utils.callbacks import *\n",
    "from src.utils.fmm import get_waves_from_fmm_model,sort_fmm_coeffs_array, get_parameters_names_list, \\\n",
    "                        get_beta_indexes, get_M_indexes, get_A_indexes,get_alpha_indexes, get_omega_indexes, \\\n",
    "                        get_circular_indexes_as_boolean_t, generate_wave, convert_fmm_array_to_dict, \\\n",
    "                        reconstruct_FMM_leads_from_FMM_array, get_loss_from_fmm_model, expand_fmm_scalar_coefficients\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate, call\n",
    "import logging \n",
    "from omegaconf import OmegaConf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "logger = logging.getLogger(__name__)\n",
    "initialize('conf',version_base=\"1.3\")\n",
    "cfg = compose(config_name='ecg_anomaly_detection.yaml',return_hydra_config=True,\n",
    "              overrides=[\"hydra.verbose=true\",\"dataset=ecg5000\",\n",
    "                         \"model=fmm_dense_ae\",\"batch_size=32\",\n",
    "                        \"optimizer=adam\",\n",
    "                        \"optimizer.learning_rate=0.00003\", \n",
    "                         \"train.num_epochs=500\",\n",
    "                         \"save_plots=True\",\n",
    "                         ]) \n",
    "set_ml_seeds(cfg.seed)\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration file\n",
    "create_folder(cfg.tb_output_dir)\n",
    "filename = os.path.join(cfg.tb_output_dir,f\"conf.yaml\")\n",
    "with open(filename,\"w\") as fp:\n",
    "    OmegaConf.save(config=cfg, f=fp)\n",
    "#Image saving function\n",
    "def save_png_eps_figure(filename):\n",
    "    if(cfg.save_plots):\n",
    "        full_filename = os.path.join(cfg.tb_output_dir,filename)\n",
    "        plt.savefig(full_filename+\".png\")\n",
    "        plt.savefig(full_filename+\".eps\")\n",
    "#Dict saving function\n",
    "def save_dict(in_dict, filename):\n",
    "    if(cfg.save_plots):\n",
    "        full_filename = os.path.join(cfg.tb_output_dir,filename)\n",
    "        save_dict_to_binary(in_dict,full_filename)\n",
    "#Numpy saving function\n",
    "def save_np(np_array, filename):\n",
    "    if(cfg.save_plots):\n",
    "        full_filename = os.path.join(cfg.tb_output_dir,filename)\n",
    "        np.save(full_filename, np_array)\n",
    "# Model names\n",
    "fmm_model_names = [\"fmm_bert_ecg\",\"fmm_cae\", \"fmm_encdec_ad\", \"fmm_lstm_ae\", \"fmm_ecgnet\", \"fmm_dense_ae\"]\n",
    "non_ae_baseline_models = [\"diffusion_ae\" ,\"ecg_adgan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset and dataset parameters\n",
    "raw_dataset_dict = call(cfg.dataset.load_function,_recursive_=False)\n",
    "data = raw_dataset_dict[\"train\"][\"data\"] \n",
    "labels = raw_dataset_dict[\"train\"][\"labels\"] \n",
    "test_data = raw_dataset_dict[\"test\"][\"data\"] \n",
    "test_labels = raw_dataset_dict[\"test\"][\"labels\"] \n",
    "normal_class = raw_dataset_dict[\"params\"][\"normal_class\"]\n",
    "leg = raw_dataset_dict[\"params\"][\"classes\"]\n",
    "subplot_ecg(data,labels,num_to_plot=9,lead=0,indexes=range(9))\n",
    "save_png_eps_figure(\"inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some example time series\n",
    "sample_index_list = np.random.randint(0,raw_dataset_dict[\"train\"][\"data\"].shape[0],(9))\n",
    "if(cfg.dataset.name in [\"ptb_xl_fmm\",\"shaoxing_fmm\"]):\n",
    "    lead = 0\n",
    "    for sample_index in sample_index_list:\n",
    "        original_seq = raw_dataset_dict[\"train\"][\"data\"][sample_index] \n",
    "        fmm_coeff_array = raw_dataset_dict[\"train\"][\"coefficients\"][sample_index] \n",
    "        seq_len = int(raw_dataset_dict[\"train\"][\"sizes\"][sample_index])\n",
    "        seq_label = leg[raw_dataset_dict[\"train\"][\"labels\"][sample_index]]\n",
    "        plt.figure()\n",
    "        sequence_len = np.squeeze(original_seq).shape[0]\n",
    "        xaxis = np.arange(1,seq_len+1)/cfg.dataset.fs \n",
    "        waves = np.zeros((sequence_len,5))\n",
    "        fmm_dict = convert_fmm_array_to_dict(fmm_array=fmm_coeff_array,num_leads=cfg.dataset.num_features,num_waves=5)\n",
    "        for i,wave_name in enumerate([\"P\",\"Q\",\"R\",\"S\",\"T\"]):\n",
    "            wave = np.squeeze(generate_wave(fmm_dict,wave_name=wave_name,lead=lead,seq_len=seq_len))\n",
    "            waves[0:seq_len,i]=wave\n",
    "        plt.plot(xaxis,original_seq[:seq_len,lead],label=f\"original\",color=\"b\",linewidth=2.0)\n",
    "        plt.plot(xaxis,fmm_dict[\"P\"][\"M\"][lead] + np.sum(waves,axis=1)[:seq_len],label=f\"Reconstruction\",color=\"r\", linewidth=2.0)\n",
    "        for j,w in enumerate([\"P\",\"Q\",\"R\",\"S\",\"T\"]):\n",
    "            plt.plot(xaxis,np.squeeze(waves[:,j])[:seq_len],linestyle=\"dashed\", linewidth=1.0)\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.ylabel(\"ECG\")\n",
    "        # plt.title(f\"Data sample index: {sample_index}, class: {seq_label}\")\n",
    "        plt.legend(loc=\"best\",fontsize=9)\n",
    "        save_png_eps_figure(f\"fmm_waves_original_{sample_index}_class_{seq_label}_lead_{lead}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "train_dict = call(cfg.dataset.preprocess_function, input_data=raw_dataset_dict[\"train\"], dataset_params=raw_dataset_dict[\"params\"]) \n",
    "test_dict = call(cfg.dataset.preprocess_function, input_data=raw_dataset_dict[\"test\"], dataset_params=raw_dataset_dict[\"params\"]) \n",
    "if(cfg.model.name in non_ae_baseline_models):\n",
    "    # Get train and validation dataset\n",
    "    train_dataset, val_dataset = get_only_normal_train_val_dataset(in_dict=train_dict, normal_class=normal_class,\n",
    "                                                                    batch_size=cfg.batch_size, seed=cfg.seed, \n",
    "                                                                    only_normal=cfg.dataset.select_only_normal, val_size=0.0,\n",
    "                                                                    return_type=\"dict\")\n",
    "    test_dataset = test_dict\n",
    "else:\n",
    "    # Get train and validation dataset\n",
    "    train_dataset, val_dataset = get_only_normal_train_val_dataset(in_dict=train_dict, normal_class=normal_class,\n",
    "                                                                    batch_size=cfg.batch_size, seed=cfg.seed, \n",
    "                                                                    only_normal=cfg.dataset.select_only_normal, val_size=cfg.dataset.val_size)\n",
    "    #Get test dataset\n",
    "    test_dataset = Dataset.from_tensor_slices(test_dict).batch(cfg.batch_size,drop_remainder=True).prefetch(10)\n",
    "# Compute coefficients parameters for the dataset and set them in the configuration file\n",
    "if(cfg.model.name in fmm_model_names):\n",
    "    if(cfg.dataset.name in [\"ptb_xl_fmm\",\"shaoxing_fmm\"]):\n",
    "        train_coeffs = train_dict[\"coefficients\"][train_dict[\"labels\"]==normal_class,:] if cfg.dataset.select_only_normal else train_dict[\"coefficients\"]\n",
    "        cfg.model.coeffs_properties_dict = get_statistics_dict_from_matrix(train_coeffs)\n",
    "    elif(cfg.dataset.name in [\"ecg5000\"]):\n",
    "        cfg.model.coeffs_properties_dict = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if model inference works\n",
    "model = instantiate(cfg.model)\n",
    "model.test_step({k: v[:cfg.batch_size] for k,v in train_dict.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile model\n",
    "model = instantiate(cfg.model)\n",
    "optimizer = instantiate(cfg.optimizer)\n",
    "model.compile(optimizer=optimizer)\n",
    "# Learning rate scheduler with decay\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    elif epoch < 15:\n",
    "        return lr * tf.math.exp(-0.05)\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.001)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "history_warmup = None\n",
    "warmup_time = 0.0   # Needed to keep track of training times\n",
    "warmup_epoch_training_times = []\n",
    "if(model.need_warmup):\n",
    "    #Warmup phase for coefficient regression\n",
    "    print(\"Starting warmup\")\n",
    "    lr_callback_warmup = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    callbacks_warmup = [\n",
    "    instantiate(cfg.dataset.es_callback),\n",
    "    lr_callback_warmup,\n",
    "    cp_cb_generator(os.path.join(cfg.tb_output_dir,\"checkpoint_warmup\")),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=cfg.tb_output_dir, histogram_freq=1),\n",
    "    TrainingTimeCallback()\n",
    "    ] \n",
    "    if(cfg.model.name in [\"cvae\"]):\n",
    "        #Only reconstruction error phase as warmup for variational autoencoder (no KL divergence loss)\n",
    "        model.alpha, model.beta = 1.0, 0.0\n",
    "    elif(cfg.model.name in fmm_model_names):\n",
    "        model.reconstruction_loss_weight, model.coefficient_loss_weight = 0.0, 1.0\n",
    "    start_warmup_time = time.time()\n",
    "    history_warmup = model.fit(train_dataset,epochs=cfg.model.num_warmup_epochs,\n",
    "                               validation_data=val_dataset,callbacks=callbacks_warmup)\n",
    "    end_warmup_time = time.time()\n",
    "    warmup_time = end_warmup_time-start_warmup_time\n",
    "    warmup_epoch_training_times = callbacks_warmup[4].epoch_times\n",
    "    model = instantiate(cfg.model)\n",
    "    model.load_weights(os.path.join(cfg.tb_output_dir,\"checkpoint_warmup\"))\n",
    "    optimizer = instantiate(cfg.optimizer)\n",
    "    model.compile(optimizer=optimizer)\n",
    "    K.set_value(model.optimizer.lr, cfg.optimizer.learning_rate)\n",
    "    if(cfg.model.name in [\"cvae\"]):\n",
    "        model.alpha, model.beta = 1.0, 1.0\n",
    "    elif(cfg.model.name in fmm_model_names):\n",
    "        model.reconstruction_loss_weight, model.coefficient_loss_weight = 1.0, 0.0\n",
    "    print(\"Ending warmup\")\n",
    "callbacks = [\n",
    "    instantiate(cfg.dataset.es_callback),\n",
    "    lr_callback,\n",
    "    cp_cb_generator(os.path.join(cfg.tb_output_dir,\"checkpoint_ad\")),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=cfg.tb_output_dir, histogram_freq=1),\n",
    "    TrainingTimeCallback()\n",
    "]\n",
    "train_time = 0.0\n",
    "train_epoch_training_times = []\n",
    "history = None\n",
    "if(cfg.train.num_epochs>0):\n",
    "    start_train_time = time.time()\n",
    "    history = model.fit(train_dataset,epochs=cfg.train.num_epochs,validation_data=val_dataset,callbacks=callbacks)\n",
    "    end_train_time = time.time()\n",
    "    train_time = end_train_time-start_train_time\n",
    "    train_epoch_training_times = callbacks[4].epoch_times\n",
    "save_dict({\"train_time\":train_time,\"warmup_time\":warmup_time,\n",
    "           \"warmup_epochs_time\":warmup_epoch_training_times,\n",
    "           \"train_epochs_time\":train_epoch_training_times,\n",
    "           },\"train_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model from checkpoint\n",
    "# cfg.model.coeffs_properties_dict = None\n",
    "model = instantiate(cfg.model)\n",
    "try:\n",
    "    checkpoint_path = os.path.join(cfg.tb_output_dir,\"checkpoint_ad\") #Restore best model \n",
    "    model.load_weights(checkpoint_path).expect_partial()\n",
    "except:\n",
    "    print(\"Loading warmup model because no anomaly detection checkpoint was found\")\n",
    "    checkpoint_path = os.path.join(cfg.tb_output_dir,\"checkpoint_warmup\") #Restore best model in only warmup case\n",
    "    model.load_weights(checkpoint_path).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(cfg.model.name in fmm_model_names):\n",
    "    loss_matrix_dict = get_loss_from_fmm_model(model,test_dataset,cfg,True)\n",
    "    print(np.mean(loss_matrix_dict[\"loss_matrix\"],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot waves and get predicted coefficient for TEST dataset\n",
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    predict_results_dict = model.predict(test_dataset)\n",
    "    original = predict_results_dict[\"data\"]\n",
    "    reconstruction = predict_results_dict[\"predicted_data\"]\n",
    "    sample_index_list = np.random.randint(0,len(test_dict[\"inputs\"]),(20))\n",
    "    lead = 0 # Plot always the first lead if there are multiple\n",
    "    if(cfg.model.name in fmm_model_names):\n",
    "        waves,fmm_coeff_matrix = get_waves_from_fmm_model(model,test_dataset,cfg)\n",
    "        m_start_index,m_end_index = get_M_indexes(wave_index=None,num_leads=cfg.dataset.num_features,num_waves=5)\n",
    "        for sample_index in sample_index_list:\n",
    "            plt.figure()\n",
    "            sample_zero_indexes = np.where(original[sample_index,:,lead]==0)[0]\n",
    "            sequence_len = sample_zero_indexes[0] if (len(sample_zero_indexes)>0) else original.shape[1]\n",
    "            xaxis = np.arange(1,sequence_len+1)/cfg.dataset.fs\n",
    "            sample_label = leg[test_dict[\"labels\"][sample_index]]\n",
    "            plt.plot(xaxis,np.squeeze(original[sample_index,:sequence_len,lead]),label=f\"original\",color=\"b\",linewidth=2.0)\n",
    "            plt.plot(xaxis,fmm_coeff_matrix[sample_index,m_start_index+lead] + np.sum(waves[sample_index,:sequence_len,lead,:],axis=1),label=f\"reconstruction\",color=\"r\", linewidth=2.0)\n",
    "            for j,w in enumerate([\"P\",\"Q\",\"R\",\"S\",\"T\"]):\n",
    "                plt.plot(xaxis,np.squeeze(waves[sample_index,:sequence_len,lead,j]),linestyle=\"dashed\", linewidth=1.0)\n",
    "            plt.xlabel(\"Time [s]\")\n",
    "            plt.ylabel(\"ECG\")\n",
    "            plt.title(f\"Data sample index: {sample_index}, class: {sample_label}, lead: {lead}\")\n",
    "            plt.legend(loc=\"upper right\")\n",
    "            save_png_eps_figure(f\"fmm_waves_{sample_index}_class_{sample_label}_lead_{lead}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter histograms for each lead\n",
    "if(cfg.model.name in fmm_model_names and cfg.dataset.name in [\"ptb_xl_fmm\",\"shaoxing_fmm\"]):\n",
    "    beta_indexes = [get_beta_indexes(wave_index=i,num_leads=cfg.dataset.num_features,num_waves=cfg.dataset.num_waves)[0] for i in range(cfg.dataset.num_waves)]\n",
    "    m_index = get_M_indexes(wave_index=i,num_leads=cfg.dataset.num_features,num_waves=cfg.dataset.num_waves)[0]\n",
    "    a_indexes = [get_A_indexes(wave_index=i,num_leads=cfg.dataset.num_features,num_waves=cfg.dataset.num_waves)[0] for i in range(cfg.dataset.num_waves)]\n",
    "    alpha_indexes = [get_alpha_indexes(wave_index=i,num_leads=cfg.dataset.num_features,num_waves=cfg.dataset.num_waves)[0] for i in range(cfg.dataset.num_waves)]\n",
    "    omega_indexes = [get_omega_indexes(wave_index=i,num_leads=cfg.dataset.num_features,num_waves=cfg.dataset.num_waves)[0] for i in range(cfg.dataset.num_waves)]\n",
    "    for fmm_model_coefficients,fmm_model_type in zip([test_dict[\"coefficients\"],fmm_coeff_matrix],[\"Original\", \"Predicted\"]):\n",
    "        for f,coeff_name in zip([get_A_indexes,get_alpha_indexes,get_beta_indexes,get_omega_indexes],[\"A\",\"Alpha\",\"Beta\",\"Omega\"]):\n",
    "            for wave_index in range(cfg.dataset.num_waves):\n",
    "                num_lead_indexes_per_parameter = 1 if coeff_name in [\"Alpha\", \"Omega\"] else cfg.dataset.num_features\n",
    "                for lead_index in range(num_lead_indexes_per_parameter):\n",
    "                    coeff_index = f(wave_index=wave_index,num_leads=cfg.dataset.num_features,num_waves=cfg.dataset.num_waves)[0]+lead_index\n",
    "                    plt.figure()\n",
    "                    vals = fmm_model_coefficients[test_dict[\"labels\"]==normal_class,coeff_index]\n",
    "                    plt.hist(vals,bins=50)\n",
    "                    plt.title(f\"{fmm_model_type} {coeff_name}_{wave_index}_{lead_index}\")\n",
    "                    plt.xlabel(\"Value\")\n",
    "                    plt.ylabel(\"Occurrences\")\n",
    "                    print(coeff_name,wave_index,np.average(vals),np.std(vals),np.average(vals)+np.std(vals))\n",
    "                    save_png_eps_figure(f\"fmm_histogram_coeff_{fmm_model_type}_{coeff_name}_wave_{wave_index}_lead_{lead_index}\")\n",
    "        for lead_index in range(cfg.dataset.num_features):\n",
    "            coeff_index = get_M_indexes(wave_index=None,num_leads=cfg.dataset.num_features,num_waves=cfg.dataset.num_waves)[0] + lead_index\n",
    "            plt.figure()\n",
    "            vals = fmm_model_coefficients[test_dict[\"labels\"]==normal_class,coeff_index]\n",
    "            plt.hist(vals,bins=50)\n",
    "            plt.title(f\"{fmm_model_type} M, lead: {lead_index}\")\n",
    "            plt.xlabel(\"Value\")\n",
    "            plt.ylabel(\"Occurrences\")\n",
    "            save_png_eps_figure(f\"fmm_histogram_coeff_{fmm_model_type}_M_wave_{wave_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation of predicted coefficients to the original coefficients (obtained through FMM optimization)\n",
    "if(cfg.model.name in fmm_model_names and cfg.dataset.name in [\"ptb_xl_fmm\",\"shaoxing_fmm\"]):\n",
    "    original_test_fmm_coefficients = test_dict[\"coefficients\"]\n",
    "    sorted_test_predicted_coefficients = sort_fmm_coeffs_array(fmm_coeff_matrix, num_leads=cfg.dataset.num_features, num_waves=5)\n",
    "    sorted_test_coefficients = sort_fmm_coeffs_array(original_test_fmm_coefficients, num_leads=cfg.dataset.num_features, num_waves=5)\n",
    "    coefficients_names = get_parameters_names_list(cfg.dataset.num_features,cfg.dataset.num_waves)\n",
    "    circular_indexes = get_circular_indexes_as_boolean_t(cfg.dataset.num_features,cfg.dataset.num_waves).numpy()\n",
    "    correlation_coefficients_pred_orig_fmm_no_sort = mixed_lin_circ_corr_coeff(\n",
    "                x=original_test_fmm_coefficients[test_dict[\"labels\"]==normal_class], \\\n",
    "                y=fmm_coeff_matrix[test_dict[\"labels\"]==normal_class],\n",
    "                c=circular_indexes)\n",
    "    correlation_coefficients_pred_orig_fmm_no_sort_dict = {n:v for n,v in zip(coefficients_names,correlation_coefficients_pred_orig_fmm_no_sort)}\n",
    "    filename = os.path.join(cfg.tb_output_dir,f\"correlation_normal_no_sorted\")\n",
    "    json.dump(correlation_coefficients_pred_orig_fmm_no_sort_dict, open(filename,\"w\"),indent=0) \n",
    "    df = pd.DataFrame([correlation_coefficients_pred_orig_fmm_no_sort_dict])\n",
    "    print(correlation_coefficients_pred_orig_fmm_no_sort_dict)\n",
    "    sorted_test_coefficients_normal = sorted_test_coefficients[test_dict[\"labels\"]==normal_class]\n",
    "    sorted_test_predicted_coefficients_normal = sorted_test_predicted_coefficients[test_dict[\"labels\"]==normal_class]\n",
    "    correlation_coefficients_pred_orig_fmm = mixed_lin_circ_corr_coeff(\n",
    "                x=sorted_test_coefficients_normal, \\\n",
    "                y=sorted_test_predicted_coefficients_normal,\n",
    "                c=circular_indexes)\n",
    "    correlation_coefficients_pred_orig_fmm_dict = {n:v for n,v in zip(coefficients_names,correlation_coefficients_pred_orig_fmm)}\n",
    "    filename = os.path.join(cfg.tb_output_dir,f\"correlation_normal_sorted\")\n",
    "    json.dump(correlation_coefficients_pred_orig_fmm_no_sort_dict, open(filename,\"w\"),indent=0) \n",
    "    print(list(zip(coefficients_names,correlation_coefficients_pred_orig_fmm)))\n",
    "    #Plot dictionaries and save them\n",
    "    plot_scalar_dictionary(correlation_coefficients_pred_orig_fmm_no_sort_dict)\n",
    "    save_png_eps_figure(\"pred_orig_corr_coeff_no_sorted\")\n",
    "    plot_scalar_dictionary(correlation_coefficients_pred_orig_fmm_dict)\n",
    "    save_png_eps_figure(\"pred_orig_corr_coeff_sorted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(cfg.model.name in fmm_model_names and cfg.dataset.name in [\"ptb_xl_fmm\",\"shaoxing_fmm\"]):\n",
    "    for sample_index in sample_index_list:\n",
    "        to_plot_original = sorted_test_coefficients[sample_index]\n",
    "        to_plot_label = leg[test_dict[\"labels\"][sample_index]]\n",
    "        plt.figure()\n",
    "        sample_len = int(test_dict[\"sizes\"][sample_index])\n",
    "        xaxis = np.arange(1,sample_len+1)/cfg.dataset.fs \n",
    "        plt.plot(xaxis,test_dict[\"inputs\"][sample_index, :sample_len, lead], label=\"ECG Input\")\n",
    "        plot_fmm_wave_from_coefficients(fmm_coeff_array=to_plot_original,\n",
    "                                        num_leads=cfg.dataset.num_features,\n",
    "                                        seq_len=sample_len,\n",
    "                                        fs=cfg.dataset.fs,\n",
    "                                        lead=lead,\n",
    "                                        add_single_waves=False,\n",
    "                                        label=\"Original FMM\")\n",
    "        plt.title(\"Original sorted FMM coefficients\")\n",
    "        sorted_test_predicted_coefficients = sort_fmm_coeffs_array(fmm_coeff_matrix, num_leads=cfg.dataset.num_features, num_waves=5)\n",
    "        to_plot_pred = sorted_test_predicted_coefficients[sample_index]\n",
    "        plot_fmm_wave_from_coefficients(fmm_coeff_array=to_plot_pred,\n",
    "                                        num_leads=cfg.dataset.num_features,\n",
    "                                        seq_len=sample_len,\n",
    "                                        fs = cfg.dataset.fs,\n",
    "                                        lead=lead,\n",
    "                                        add_single_waves=False,\n",
    "                                        label=\"Predicted FMM\")\n",
    "        plt.title(f\"Predicted sorted FMM coefficients, sample {sample_index}, class {to_plot_label}, lead: {lead}\")\n",
    "    sample_index=100\n",
    "    coefficients_dict = {}\n",
    "    for a,b,name in zip(sorted_test_coefficients_normal[sample_index],\n",
    "                        sorted_test_predicted_coefficients_normal[sample_index],\n",
    "                        coefficients_names):\n",
    "        print(f\"{name}: \\n \\t original: {a}, \\n \\t predicted: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    for sample_index in sample_index_list:\n",
    "        plt.figure()\n",
    "        sequence_len = np.squeeze(original[sample_index,:,lead]).shape[0]\n",
    "        sample_len = int(test_dict[\"sizes\"][sample_index])\n",
    "        xaxis = np.arange(1,sample_len+1)/cfg.dataset.fs\n",
    "        sample_label = leg[test_dict[\"labels\"][sample_index]]\n",
    "        plt.plot(xaxis,np.squeeze(original[sample_index,:sample_len,lead]),label=f\"{sample_index}\",color=\"b\")\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.ylabel(\"ECG\")\n",
    "        plt.title(f\"Data sample index: {sample_index}, class: {sample_label}\")\n",
    "        if(cfg.save_plots):\n",
    "            filename = os.path.join(cfg.tb_output_dir,f\"original_{sample_index}\")\n",
    "            plt.savefig(filename+\".png\")\n",
    "            plt.savefig(filename+\".eps\")\n",
    "        plt.figure()\n",
    "        plt.plot(xaxis,np.squeeze(reconstruction[sample_index,:sample_len,lead]),label=f\"{sample_index}\",color=\"r\")\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.ylabel(\"ECG\")\n",
    "        plt.title(f\"Data sample index: {sample_index}, class: {sample_label}\")\n",
    "        save_png_eps_figure(f\"reconstruction_{sample_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    for sample_index in sample_index_list:\n",
    "        plt.figure()\n",
    "        sequence_len = np.squeeze(original[sample_index,:,lead]).shape[0]\n",
    "        xaxis = np.arange(1,sequence_len+1)/cfg.dataset.fs\n",
    "        sample_label = leg[test_dict[\"labels\"][sample_index]]\n",
    "        plt.plot(xaxis,np.squeeze(original[sample_index,:,lead]),label=f\"original_{sample_index}\",color=\"b\")\n",
    "        plt.plot(xaxis,np.squeeze(reconstruction[sample_index,:,lead]),label=f\"reconstruction_{sample_index}\",color=\"r\")\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.ylabel(\"ECG\")\n",
    "        plt.title(f\"Data sample index: {sample_index}, class: {sample_label}, lead {lead}\")\n",
    "        plt.legend()\n",
    "        if(cfg.save_plots):\n",
    "            filename = os.path.join(cfg.tb_output_dir,f\"original_recons_{sample_index}\")\n",
    "            plt.savefig(filename+\".png\")\n",
    "            plt.savefig(filename+\".eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    plt.figure()\n",
    "    for sample_index in range(10):\n",
    "        sequence_len = np.squeeze(original[sample_index]).shape[0]\n",
    "        xaxis = np.arange(1,sequence_len+1)/cfg.dataset.fs\n",
    "        plt.plot(xaxis,np.squeeze(original[sample_index,:,lead]),label=f\"{sample_index}\",color=\"b\")\n",
    "        plt.plot(xaxis,np.squeeze(reconstruction[sample_index,:,lead]),label=f\"{sample_index}\",color=\"y\")\n",
    "    plt.title(\"Model prediction vs original data\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"ECG\")\n",
    "    plt.legend()\n",
    "    save_png_eps_figure(f\"reconstruction_check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def history_plot_fun(history, file_name):\n",
    "    plt.figure()\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    if(cfg.model.name==\"rythm_vae\"):\n",
    "        plot_list = [['loss','val_loss'],\n",
    "                    ['morpho_reconstruction_loss','rythm_reconstruction_loss','val_morpho_reconstruction_loss','val_rythm_reconstruction_loss'],\n",
    "                    ['morpho_kl_loss','rythm_kl_loss','val_morpho_kl_loss','val_rythm_kl_loss']]\n",
    "    elif(cfg.model.name in[\"bert_ecg\", \"conv_ae\", \"encdec_ad\", \"dense_ae\", \"lstm_ae\", \"ecgnet\"] ):\n",
    "        plot_list = [['loss','val_loss']]\n",
    "    elif(cfg.model.name in fmm_model_names):\n",
    "        plot_list = [['loss','val_loss'],['reconstruction_loss','val_reconstruction_loss'],['coefficient_loss','val_coefficient_loss']]\n",
    "    elif(cfg.model.name==\"ecg_adgan\"):\n",
    "        plot_list = [['D_loss','G_loss'],['acc']]\n",
    "    elif(cfg.model.name==\"diffusion_ae\"):\n",
    "        plot_list = [['sum_loss_train','ae_loss_train','diff_loss_train']]\n",
    "    else:\n",
    "        plot_list = [['loss','val_loss'],['reconstruction_loss','val_reconstruction_loss'],['kl_loss','val_kl_loss']]\n",
    "    for i,metric_to_plot_list in enumerate(plot_list):\n",
    "        ax = plt.subplot(len(plot_list),1,i+1)\n",
    "        for metric_to_plot in metric_to_plot_list:\n",
    "            to_plot = history.history[metric_to_plot]\n",
    "            ax.plot(to_plot,label=metric_to_plot)\n",
    "        plt.legend()\n",
    "        ax.set_title(metric_to_plot_list[0].capitalize())\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        if(i!=len(plot_list)-1):\n",
    "            ax.tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    if(cfg.save_plots):\n",
    "        filename = os.path.join(cfg.tb_output_dir,f\"{file_name}.json\")\n",
    "        with open(filename,\"wb\") as f: \n",
    "            pickle.dump(history.history,f)\n",
    "        save_png_eps_figure(f\"{file_name}\")\n",
    "if(history is not None):\n",
    "    history_plot_fun(history=history, file_name=\"history\")\n",
    "if(history_warmup is not None):\n",
    "    history_plot_fun(history=history_warmup, file_name=\"history_warmup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and test losses\n",
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    train_class_loss_dict = get_loss_score(in_vae=model,data_dict=train_dict,batch_size=cfg.batch_size,classes=leg,num_samples=-1)\n",
    "    test_class_loss_dict = get_loss_score(in_vae=model,data_dict=test_dict,batch_size=cfg.batch_size,classes=leg,num_samples=-1)\n",
    "else:\n",
    "    train_class_loss_dict = model.compute_class_loss(train_dict, leg)\n",
    "    test_class_loss_dict = model.compute_class_loss(test_dict, leg)\n",
    "print(f\"Train: {train_class_loss_dict} \\nTest:{test_class_loss_dict}\")\n",
    "print(\"Normal class mean accuracy train/test : {0},{1}\".format(train_class_loss_dict[\"mean\"][normal_class], test_class_loss_dict[\"mean\"][normal_class]))\n",
    "if(cfg.save_plots):\n",
    "    filename = os.path.join(cfg.tb_output_dir,f\"train_class_loss\")\n",
    "    json.dump(train_class_loss_dict, open(filename,\"w\"),indent=0)  \n",
    "    filename = os.path.join(cfg.tb_output_dir,f\"test_class_loss\")\n",
    "    json.dump(test_class_loss_dict, open(filename,\"w\"),indent=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for an example threshold\n",
    "threshold = train_class_loss_dict[\"mean\"][normal_class]+0.05*train_class_loss_dict[\"std\"][normal_class]\n",
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    test_confusion_matrix = get_confusion_matrix(in_vae=model,data_dict=test_dict,\n",
    "                                                batch_size=cfg.batch_size,threshold=threshold,\n",
    "                                                classes=leg,normal_class=normal_class)\n",
    "else:\n",
    "    test_confusion_matrix = model.get_confusion_matrix(test_dict, threshold, normal_class)\n",
    "print(test_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and test roc curve\n",
    "train_roc_filename = os.path.join(cfg.tb_output_dir,f\"train_roc\") if cfg.save_plots else None \n",
    "test_roc_filename = os.path.join(cfg.tb_output_dir,f\"test_roc\") if cfg.save_plots else None\n",
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    train_roc_dict = get_roc_auroc(model, train_dict, cfg.batch_size, normal_class, filename=train_roc_filename)\n",
    "    test_roc_dict = get_roc_auroc(model, test_dict, cfg.batch_size, normal_class, filename=test_roc_filename)\n",
    "else:\n",
    "    train_roc_dict = model.compute_roc(train_dict, normal_class, train_roc_filename)\n",
    "    test_roc_dict = model.compute_roc(test_dict, normal_class, test_roc_filename)\n",
    "train_auc,test_auc = train_roc_dict[\"roc_auc\"], test_roc_dict[\"roc_auc\"]\n",
    "print(f\"Train AUC: {train_auc} \\nTest AUC: {test_auc}\")\n",
    "if(cfg.save_plots):\n",
    "    filename = os.path.join(cfg.tb_output_dir,f\"train_roc.json\")\n",
    "    json.dump(train_roc_dict, open(filename,\"w\"),indent=0)  \n",
    "    filename = os.path.join(cfg.tb_output_dir,f\"test_roc.json\")\n",
    "    json.dump(test_roc_dict, open(filename,\"w\"),indent=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some original and reconstructed ECGs\n",
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    filename = os.path.join(cfg.tb_output_dir,\"orig_plus_rec_train_sample\") if cfg.save_plots else None\n",
    "    plot_one_ecg_for_class(in_vae=model,data_dict=train_dict,classes=leg,filename=filename,fs=cfg.dataset.fs,batch_size=cfg.batch_size, lead=lead)\n",
    "    filename = os.path.join(cfg.tb_output_dir,\"orig_plus_rec_test_sample\") if cfg.save_plots else None\n",
    "    plot_one_ecg_for_class(in_vae=model,data_dict=test_dict,classes=leg,filename=filename,fs=cfg.dataset.fs,batch_size=cfg.batch_size, lead=lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of parameters and size of the model\n",
    "if(cfg.model.name not in non_ae_baseline_models or cfg.model.name in \"ecg_adgan\"):\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights],dtype=int)\n",
    "    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights],dtype=int)\n",
    "else:\n",
    "    trainable_count = model.get_number_trainable_parameters()\n",
    "    non_trainable_count = model.get_number_non_trainable_parameters()\n",
    "total_num_params = trainable_count + non_trainable_count\n",
    "# Get the size of the model file on disk\n",
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    model_size_bytes = os.path.getsize(checkpoint_path+\".data-00000-of-00001\")\n",
    "else:\n",
    "    model_size_bytes = model.get_model_size(os.path.dirname(callbacks[2].filepath))\n",
    "model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "model_size_dict = {\"num_trainable\": trainable_count,\n",
    "                   \"num_non_trainable\": non_trainable_count,\n",
    "                    \"num_parameters\": total_num_params,\n",
    "                    \"model_size_bytes\": model_size_bytes,\n",
    "                    \"model_size_mb\": model_size_mb,\n",
    "                    }\n",
    "save_dict(model_size_dict,\"model_size\")\n",
    "print(model_size_dict)\n",
    "# load_dict_from_binary(os.path.join(cfg.tb_output_dir,\"model_size\"))\n",
    "# Compute inference times\n",
    "inference_batch_size = 16\n",
    "if(cfg.model.name not in non_ae_baseline_models):\n",
    "    dataset = Dataset.from_tensor_slices(test_dict).batch(inference_batch_size) #Use always batch size 16 to compute inference times\n",
    "else:\n",
    "    model.batch_size = 16\n",
    "    dataset = test_dataset\n",
    "num_samples = len(dataset)  # Number of input samples\n",
    "start_predict_time = time.time()\n",
    "model.predict(dataset, verbose=None)\n",
    "end_predict_time = time.time()\n",
    "predict_time = end_predict_time - start_predict_time\n",
    "save_dict({\"num_batches\":num_samples,\"predict_time\":predict_time,\n",
    "           \"avg_predict_time\":predict_time/num_samples,\"batch_size\" :inference_batch_size},\"predict_time\")\n",
    "print(predict_time)\n",
    "# load_dict_from_binary(os.path.join(cfg.tb_output_dir,\"predict_time\"))\n",
    "# inference_times = []\n",
    "# for in_data in dataset:\n",
    "#     start_time = time.time()  # Record start time\n",
    "#     predictions = model.predict(in_data, verbose=None)  # Perform inference\n",
    "#     end_time = time.time()  # Record end time\n",
    "#     inference_time = end_time - start_time\n",
    "#     inference_times.append(inference_time)\n",
    "# inference_times = np.array(inference_times)\n",
    "# save_np(inference_times, \"inference_times\")\n",
    "# np.load(os.path.join(cfg.tb_output_dir,\"inference_times.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set completed in configuration file and save it in the experiment folder\n",
    "cfg.completed=True\n",
    "filename = os.path.join(cfg.tb_output_dir,f\"conf.yaml\")\n",
    "with open(filename,\"w\") as fp:\n",
    "    OmegaConf.save(config=cfg, f=fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5619468074b66b02b86f7f2c04d772ebb110c6715e28b9201370ab12206a02b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
